---
title: "Data Cleaning Script"
author: "Rebecca Folmer Schade & Sophia Kleist Karlson"
date: "2021-05-11 updated 2021-06-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "..")
```

## Loading packages 
```{r, results='hide', warning=FALSE, error=FALSE, message=FALSE}
# Quick install/load of all used packages if needed 
# install.packages("pacman")
# pacman::p_load(pacman, osmdata, sf, tidyverse, raster)
library(osmdata)
library(sf)
library(tidyverse)
library(raster)
```

# Data gathering and cleaning 
In this script, data on LGBT+ friendly amenities in the European Economic Area (EEA) and Switzerland is gathered from Open Street Maps and cleaned for use in the Leaflet visualization.

## Querying data from Open street maps
Data is queried withing the three bounding boxes that contain the keys gay= and lgbtq= with all associated values indicating that the location is lgbt+ friendly (gay=yes/welcome/only and lgbtq=primary/only/yes). Though the wiki for the lgbtq key discourages the use of lgbtq=yes, it still queried as some data was coded as such [(link here, last read 2021-05-25)](https://wiki.openstreetmap.org/wiki/Key:lgbtq).  

Because of the scattering of European territories, the data is queried from within three bounding boxes - one containing most of Europe, one containing the Danish territory Greenland, and one containing the French territory French Guiana.  

The dataset requested from OSM is quite large, and to avoid passing the quota of data downloaded from one IP adress, each key and value is queried separately (with a buffer of 15 minuttes between each query). As such, this process is very time consuming. Therefore, the data is queried from a separate script (which can be sourced below). This should takes approximately 30 minuttes.  
If this takes too long, or if there are any other issues, there is also the possibility of loading the raw data in the **Loading data** section below.   
Alternatively, one could change the "timeout" between each query or manually do one request at a time.

```{r, eval=FALSE}
# Sourcing the script "OSMQuery.R"
source("scripts/OSMQuery.R")

#===> Saving data in a way that is compatible with the sf package
# Removing components of the osmdata that are duplicated within the object
EEA_safe_unique <- unique_osmdata(EEA_safe_spaces)
colnames(raw_points)
# Removing unneeded variables (as datasets that have too many fields/columns are hard to save)
raw_points <- EEA_safe_unique$osm_points %>%  dplyr::select(osm_id, name, amenity, opening_hours, website)
raw_polygons <- EEA_safe_unique$osm_polygons %>%  dplyr::select(osm_id, name, amenity, opening_hours, website)
raw_lines <- EEA_safe_unique$osm_lines %>% dplyr::select(osm_id, name, amenity, opening_hours, website)
raw_multipolygons <- EEA_safe_unique$osm_multipolygons %>% dplyr::select(osm_id, name, amenity)
# Sorting out issues with encoding of characters 
raw_points$name <- iconv(raw_points$name, from = "UTF-8", to = "UTF-8")
raw_points$opening_hours <- iconv(raw_points$opening_hours, from = "UTF-8", to = "UTF-8")
#
raw_polygons$name <- iconv(raw_polygons$name, from = "UTF-8", to = "UTF-8")
raw_polygons$opening_hours <- iconv(raw_polygons$opening_hours, from = "UTF-8", to = "UTF-8")
#
raw_lines$name <- iconv(raw_lines$name, from = "UTF-8", to = "UTF-8")
raw_lines$opening_hours <- iconv(raw_lines$opening_hours, from = "UTF-8", to = "UTF-8")
# 
raw_multipolygons$name <- iconv(raw_multipolygons$name, from = "UTF-8", to = "UTF-8")
# Saving data
st_write(raw_points, "data/raw/EEA_raw_points5.shp", layer_options = "ENCODING=UTF-8", delete_layer = TRUE)
st_write(raw_polygons, "data/raw/EEA_raw_polygons5.shp", layer_options = "ENCODING=UTF-8", delete_layer = TRUE)
st_write(raw_lines, "data/raw/EEA_raw_lines5.shp", layer_options = "ENCODING=UTF-8", delete_layer = TRUE)
st_write(raw_multipolygons, "data/raw/EEA_raw_multipolygons5.shp", layer_options = "ENCODING=UTF-8", delete_layer = TRUE)
```

## Loading data

```{r, results='hide', warning=FALSE, message=FALSE, error=FALSE}
# Loading data for cleaning 
raw_points <- st_read("data/raw/EEA_raw_points.shp", options = "ENCODING=UTF-8")
raw_polygons <- st_read("data/raw/EEA_raw_polygons.shp", options = "ENCODING=UTF-8")
raw_lines <- st_read("data/raw/EEA_raw_lines.shp", options = "ENCODING=UTF-8")
raw_multipolygons <- st_read("data/raw/EEA_raw_multipolygons.shp", options = "ENCODING=UTF-8")
```

## Cleaning the data
### Creating a map of countries in the EEA (+ Switzerland)
While the main visualizations are made in leaflet, this is useful for quick illustrations and subsetting data. 
The map is made with data from [naturalearthdata.com](https://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-0-details/) (@ naturalearthdata.com.). 

```{r, results='hide', warning=FALSE, error=FALSE, message=FALSE}
# loading data from eurostat 
world_geo <- st_read("data/ne_10m_admin_0_sovereignty/ne_10m_admin_0_sovereignty.shp")
world_geo <- st_read("data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp")
head(world_geo)

# Let's try plotting the data 
plot(st_geometry(world_geo))

Denmark <- world_geo[world_geo$NAME_EN == 'Denmark',]
ggplot() + geom_sf(data = Denmark) + theme_bw()


# Creating a list of countries that are members of the EEA 
EEA_members <- c("Austria", "Belgium", "Bulgaria", "Croatia", "Cyprus", "Czechia", "Denmark", "Estonia", "Finland", "France", "Germany", "Greece", "Hungary", "Iceland", "Ireland", "Italy", "Latvia", "Liechtenstein", "Lithuania", "Luxembourg", "Malta", "Netherlands", "Norway", "Poland", "Portugal", "Romania", "Slovakia", "Slovenia", "Spain", "Sweden", "Switzerland")
# > With the excption of Switzerland, the list was taken from https://ec.europa.eu/eurostat/statistics-explained/index.php?title=Glossary:European_Economic_Area_(EEA) (2021-05-25)

# Checking to see if Anything was overlooked in this list 
sort(unique(world_geo$NAME_EN))
# > Everything seems to be in order

# Checking that all countries in the EEA_members list are present in the dataset 
EEA_members %in% world_geo$NAME_EN
# > the sixth country on the list (Czechia) is registered in the world_geo dataset as "Czech Republic"

# Changing item 6 to "Czech Republic""
EEA_members[6] <- "Czech Republic"

# Creating a map only with the countries in the EEA for subsetting data later on
EEA_geo <- world_geo %>% dplyr::filter(NAME_EN %in% EEA_members)

# Showing EEA territories in a plot 
plot(st_geometry(world_geo));plot(st_geometry(EEA_geo), col = "red", fil = "red", add = TRUE)

# Projections are changed to ETRS89-extended / LAEA Europe to make data wrangeling easier 
world_geo <- world_geo %>% 
  st_transform(crs = 3035)
EEA_geo <- EEA_geo %>% 
  st_transform(crs = 3035)

# checking that it worked 
plot(st_geometry(world_geo));plot(st_geometry(EEA_geo), col = "red", fil = "red", add = TRUE)
```

### Transforming, merging, and subsetting data 

```{r, results='hide', warning=FALSE, error=FALSE, message=FALSE}
# Isolate the points and change projection 
EEA_rpoint <- raw_points %>%
  st_transform(crs = 3035) 

# Change the projecttion, isolate the polygons Compute centroids of the polygons, and store data as points 
EEA_rpoly  <- raw_polygons %>% 
  st_transform(crs = 3035) %>% 
  st_centroid()

# > the lines and multipolygons are saved in separate objects because thay are unexpected in the query, and will be examined separately 
EEA_rline <- raw_lines %>% 
  st_transform(crs = 3035)
EEA_rmultipoly <- raw_multipolygons %>% 
  st_transform(crs = 3035)

# Merging
EEA_safe_osm <- rbind(EEA_rpoly,EEA_rpoint)

# Remove points outside the area of interest
EEA_safe_osm_filtered <- st_intersection(EEA_safe_osm, (EEA_geo %>% st_geometry() %>% st_union()))
```

### Having a look at the lines and multipolygons 

```{r}
# Looking at multipolygons
head(EEA_rmultipoly)
# Looking at linestrings
head(EEA_rline)
```

When one looks at the dataframes themselves, one can see that the lines lack values in most of the columns we found relevant, and that the multypolugons lack the columns for most of these categories to begin with. Given this (and that we are not sure what these geometries are supposed to represent to begin with), we have elected to exclude them from further analysis. 

### Cleaning variables 
As these variables will be used in the visualization, they should be made a little prettier to look at. 

```{r, results='hide', warning=FALSE, error=FALSE, message=FALSE}
#=====> Cleaning EEA_point_select <=====#
#===> Cleaning $name
unique(EEA_safe_osm_filtered$name)
# > I identified two issues: Some entries with small first letters, and the use of quetation marks.
# Fixing the unneded quotation marks
EEA_safe_osm_filtered$name <- str_replace_all(EEA_safe_osm_filtered$name, pattern = "\"", replacement = "")
# Fixing the small first letters 
EEA_safe_osm_filtered$name <- str_to_title(EEA_safe_osm_filtered$name)

#===> Cleaning $amenity
unique(EEA_safe_osm_filtered$amenity)
# > two issues: the use of underscores instead of space and lack of capitalization
# Fixing the use of underscores 
EEA_safe_osm_filtered$amenity <- str_replace_all(EEA_safe_osm_filtered$amenity, pattern = "_", replacement = " ")
# Fixing the capitalization 
EEA_safe_osm_filtered$amenity <- str_to_sentence(EEA_safe_osm_filtered$amenity)
```

## Saving data 
As the lines and multypoligons were unexpected, they are saved separately for now.

```{r, eval=FALSE}
#===> Saving data in the data folder
st_write(EEA_safe_osm_filtered, "data/EEA_points.shp")
```
